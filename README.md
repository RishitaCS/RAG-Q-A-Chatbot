# ğŸ§  RAG-Powered Q&A Chatbot

A smart chatbot powered by **Retrieval-Augmented Generation (RAG)** using Hugging Face models and built with Streamlit for a clean, interactive user interface.

This chatbot reads custom documents, retrieves relevant content, and generates human-like answers using generative AI â€” combining the best of search and synthesis.

---

## ğŸš€ Features

- ğŸ“„ **Document Uploading** â€“ Add your own `.txt` files
- ğŸ” **Semantic Search** â€“ Uses embeddings to retrieve the most relevant context
- ğŸ’¬ **LLM-Powered Answers** â€“ Uses `google/flan-t5-base` to generate coherent, factual answers
- ğŸ–¥ï¸ **Streamlit UI** â€“ Clean, user-friendly interface with chat history
- ğŸ§  **Memory-Powered** â€“ Maintains a chat history per session for continuity
- âš™ï¸ **Lightweight & Fast** â€“ Designed to run on Colab or CPU environments

---

## ğŸŒ Live Demo

ğŸ‘‰ [Click here to try the chatbot app](https://rag-q-a-chatbot-exhgbwzj9wc9k58wxmjqed.streamlit.app/)

> Note: It may take a few seconds to load as it initializes the model on CPU.

## ğŸ“ Folder Structure
RAG-Q-A-Chatbot/
â”‚
â”œâ”€â”€ app.py                  # ğŸ”· Main Streamlit app
â”œâ”€â”€ Retriever.py            # ğŸ” DocumentRetriever class
â”œâ”€â”€ Generator.py            # ğŸ§  AnswerGenerator class
â”œâ”€â”€ docs.txt                # ğŸ“„ Input documents
â”œâ”€â”€ requirements.txt        # ğŸ“¦ Dependencies for deployment
â””â”€â”€ README.md               # ğŸ“˜ Project documentation

**ğŸ“š How It Works**
1) Upload documents (default docs.txt)
2) Ask a question using the chat input
3) The system:
- Retrieves relevant context using all-MiniLM-L6-v2 embeddings
- Feeds context + question to google/flan-t5-base
- Returns an AI-generated answer
